# This file is used to manually specify the semi-automatic conversion of
# 'nipype.interfaces.niftyseg.stats.BinaryStats' from Nipype to Pydra.
#
# Please fill-in/edit the fields below where appropriate
#
# Docs
# ----
# Binary statistical operations.
# 
#     See Also
#     --------
#     `Source code <http://cmictig.cs.ucl.ac.uk/wiki/index.php/NiftySeg>`__ --
#     `Documentation <http://cmictig.cs.ucl.ac.uk/wiki/index.php/NiftySeg_documentation>`__
# 
#     Examples
#     --------
#     >>> import copy
#     >>> from nipype.interfaces import niftyseg
#     >>> binary = niftyseg.BinaryStats()
#     >>> binary.inputs.in_file = 'im1.nii'
#     >>> # Test sa operation
#     >>> binary_sa = copy.deepcopy(binary)
#     >>> binary_sa.inputs.operation = 'sa'
#     >>> binary_sa.inputs.operand_value = 2.0
#     >>> binary_sa.cmdline
#     'seg_stats im1.nii -sa 2.00000000'
#     >>> binary_sa.run()  # doctest: +SKIP
#     >>> # Test ncc operation
#     >>> binary_ncc = copy.deepcopy(binary)
#     >>> binary_ncc.inputs.operation = 'ncc'
#     >>> binary_ncc.inputs.operand_file = 'im2.nii'
#     >>> binary_ncc.cmdline
#     'seg_stats im1.nii -ncc im2.nii'
#     >>> binary_ncc.run()  # doctest: +SKIP
#     >>> # Test Nl operation
#     >>> binary_nl = copy.deepcopy(binary)
#     >>> binary_nl.inputs.operation = 'Nl'
#     >>> binary_nl.inputs.operand_file = 'output.csv'
#     >>> binary_nl.cmdline
#     'seg_stats im1.nii -Nl output.csv'
#     >>> binary_nl.run()  # doctest: +SKIP
# 
#     
task_name: BinaryStats
nipype_name: BinaryStats
nipype_module: nipype.interfaces.niftyseg.stats
inputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    operand_file: text/csv
    # type=file|default=<undefined>: second image to perform operation with
    in_file: medimage/nifti1
    # type=file|default=<undefined>: image to operate on
    mask_file: generic/file
    # type=file|default=<undefined>: statistics within the masked area
  metadata:
  # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
outputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
  callables:
  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
  # to set to the `callable` attribute of output fields
  templates:
  # dict[str, str] - `output_file_template` values to be provided to output fields
  requirements:
  # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
tests:
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    operation:
    # type=enum|default='p'|allowed['Nl','Vl','al','d','ncc','nmi','p','sa','ss','svp']: Operation to perform:      * p - <float> - The <float>th percentile of all voxels intensity (float=[0,100])     * sa - <ax> - Average of all voxels     * ss - <ax> - Standard deviation of all voxels     * svp - <ax> - Volume of all probabilsitic voxels (sum(<in>) x <volume per voxel>)     * al - <in2> - Average value in <in> for each label in <in2>     * d - <in2> - Calculate the Dice score between all classes in <in> and <in2>     * ncc - <in2> - Normalized cross correlation between <in> and <in2>     * nmi - <in2> - Normalized Mutual Information between <in> and <in2>     * Vl - <csv> - Volume of each integer label <in>. Save to <csv>file.     * Nl - <csv> - Count of each label <in>. Save to <csv> file.  
    operand_file:
    # type=file|default=<undefined>: second image to perform operation with
    operand_value:
    # type=float|default=0.0: value to perform operation with
    in_file:
    # type=file|default=<undefined>: image to operate on
    mask_file:
    # type=file|default=<undefined>: statistics within the masked area
    larger_voxel:
    # type=float|default=0.0: Only estimate statistics if voxel is larger than <float>
    args:
    # type=str|default='': Additional parameters to the command
    environ:
    # type=dict|default={}: Environment variables
  imports:
  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    in_file:
    # type=file|default=<undefined>: image to operate on
    operation: '"Nl"'
    # type=enum|default='p'|allowed['Nl','Vl','al','d','ncc','nmi','p','sa','ss','svp']: Operation to perform:      * p - <float> - The <float>th percentile of all voxels intensity (float=[0,100])     * sa - <ax> - Average of all voxels     * ss - <ax> - Standard deviation of all voxels     * svp - <ax> - Volume of all probabilsitic voxels (sum(<in>) x <volume per voxel>)     * al - <in2> - Average value in <in> for each label in <in2>     * d - <in2> - Calculate the Dice score between all classes in <in> and <in2>     * ncc - <in2> - Normalized cross correlation between <in> and <in2>     * nmi - <in2> - Normalized Mutual Information between <in> and <in2>     * Vl - <csv> - Volume of each integer label <in>. Save to <csv>file.     * Nl - <csv> - Count of each label <in>. Save to <csv> file.  
    operand_value: '2.0'
    # type=float|default=0.0: value to perform operation with
    operand_file:
    # type=file|default=<undefined>: second image to perform operation with
  imports: &id001
  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  - module: copy
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
doctests:
- cmdline: seg_stats im1.nii -Nl output.csv
  # str - the expected cmdline output
  inputs:
  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
  # If the field is of file-format type and the value is None, then the
  # '.mock()' method of the corresponding class is used instead.
    in_file:
    # type=file|default=<undefined>: image to operate on
    operation: '"Nl"'
    # type=enum|default='p'|allowed['Nl','Vl','al','d','ncc','nmi','p','sa','ss','svp']: Operation to perform:      * p - <float> - The <float>th percentile of all voxels intensity (float=[0,100])     * sa - <ax> - Average of all voxels     * ss - <ax> - Standard deviation of all voxels     * svp - <ax> - Volume of all probabilsitic voxels (sum(<in>) x <volume per voxel>)     * al - <in2> - Average value in <in> for each label in <in2>     * d - <in2> - Calculate the Dice score between all classes in <in> and <in2>     * ncc - <in2> - Normalized cross correlation between <in> and <in2>     * nmi - <in2> - Normalized Mutual Information between <in> and <in2>     * Vl - <csv> - Volume of each integer label <in>. Save to <csv>file.     * Nl - <csv> - Count of each label <in>. Save to <csv> file.  
    operand_value: '2.0'
    # type=float|default=0.0: value to perform operation with
    operand_file:
    # type=file|default=<undefined>: second image to perform operation with
  imports: *id001
  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  directive:
  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
