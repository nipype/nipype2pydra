# This file is used to manually specify the semi-automatic conversion of
# 'nipype.interfaces.afni.preprocess.NetCorr' from Nipype to Pydra.
#
# Please fill-in/edit the fields below where appropriate
#
# Docs
# ----
# Calculate correlation matrix of a set of ROIs (using mean time series of
#     each). Several networks may be analyzed simultaneously, one per brick.
# 
#     For complete details, see the `3dNetCorr Documentation
#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dNetCorr.html>`_.
# 
#     Examples
#     --------
#     >>> from nipype.interfaces import afni
#     >>> ncorr = afni.NetCorr()
#     >>> ncorr.inputs.in_file = 'functional.nii'
#     >>> ncorr.inputs.mask = 'mask.nii'
#     >>> ncorr.inputs.in_rois = 'maps.nii'
#     >>> ncorr.inputs.ts_wb_corr = True
#     >>> ncorr.inputs.ts_wb_Z = True
#     >>> ncorr.inputs.fish_z = True
#     >>> ncorr.inputs.out_file = 'sub0.tp1.ncorr'
#     >>> ncorr.cmdline
#     '3dNetCorr -prefix sub0.tp1.ncorr -fish_z -inset functional.nii -in_rois maps.nii -mask mask.nii -ts_wb_Z -ts_wb_corr'
#     >>> res = ncorr.run()  # doctest: +SKIP
# 
#     
task_name: NetCorr
nipype_name: NetCorr
nipype_module: nipype.interfaces.afni.preprocess
inputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    in_file: medimage/nifti1
    # type=file|default=<undefined>: input time series file (4D data set)
    in_rois: medimage/nifti1
    # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
    mask: medimage/nifti1
    # type=file|default=<undefined>: can include a whole brain mask within which to calculate correlation. Otherwise, data should be masked already
    out_file: Path
    # type=file|default=<undefined>: output file name part
    weight_ts: generic/file
    # type=file|default=<undefined>: input a 1D file WTS of weights that will be applied multiplicatively to each ROI's average time series. WTS can be a column- or row-file of values, but it must have the same length as the input time series volume. If the initial average time series was A[n] for n=0,..,(N-1) time points, then applying a set of weights W[n] of the same length from WTS would produce a new time series:  B[n] = A[n] * W[n]
  callable_defaults:
  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
  # to set as the `default` method of input fields
  metadata:
  # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
outputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    out_corr_maps: generic/file+list-of
    # type=list: output correlation maps in Pearson and/or Z-scores
    out_corr_matrix: generic/file
    # type=file: output correlation matrix between ROIs written to a text file with .netcc suffix
  callables:
  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
  # to set to the `callable` attribute of output fields
  templates:
  # dict[str, str] - `output_file_template` values to be provided to output fields
  requirements:
  # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
tests:
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    in_file:
    # type=file|default=<undefined>: input time series file (4D data set)
    in_rois:
    # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
    mask:
    # type=file|default=<undefined>: can include a whole brain mask within which to calculate correlation. Otherwise, data should be masked already
    weight_ts:
    # type=file|default=<undefined>: input a 1D file WTS of weights that will be applied multiplicatively to each ROI's average time series. WTS can be a column- or row-file of values, but it must have the same length as the input time series volume. If the initial average time series was A[n] for n=0,..,(N-1) time points, then applying a set of weights W[n] of the same length from WTS would produce a new time series:  B[n] = A[n] * W[n]
    fish_z:
    # type=bool|default=False: switch to also output a matrix of Fisher Z-transform values for the corr coefs (r): Z = atanh(r) , (with Z=4 being output along matrix diagonals where r=1, as the r-to-Z conversion is ceilinged at Z = atanh(r=0.999329) = 4, which is still *quite* a high Pearson-r value
    part_corr:
    # type=bool|default=False: output the partial correlation matrix
    ts_out:
    # type=bool|default=False: switch to output the mean time series of the ROIs that have been used to generate the correlation matrices. Output filenames mirror those of the correlation matrix files, with a '.netts' postfix
    ts_label:
    # type=bool|default=False: additional switch when using '-ts_out'. Using this option will insert the integer ROI label at the start of each line of the *.netts file created. Thus, for a time series of length N, each line will have N+1 numbers, where the first is the integer ROI label and the subsequent N are scientific notation values
    ts_indiv:
    # type=bool|default=False: switch to create a directory for each network that contains the average time series for each ROI in individual files (each file has one line). The directories are labelled PREFIX_000_INDIV/, PREFIX_001_INDIV/, etc. (one per network). Within each directory, the files are labelled ROI_001.netts, ROI_002.netts, etc., with the numbers given by the actual ROI integer labels
    ts_wb_corr:
    # type=bool|default=False: switch to create a set of whole brain correlation maps. Performs whole brain correlation for each ROI's average time series; this will automatically create a directory for each network that contains the set of whole brain correlation maps (Pearson 'r's). The directories are labelled as above for '-ts_indiv' Within each directory, the files are labelled WB_CORR_ROI_001+orig, WB_CORR_ROI_002+orig, etc., with the numbers given by the actual ROI integer labels
    ts_wb_Z:
    # type=bool|default=False: same as above in '-ts_wb_corr', except that the maps have been Fisher transformed to Z-scores the relation: Z=atanh(r). To avoid infinities in the transform, Pearson values are effectively capped at |r| = 0.999329 (where |Z| = 4.0). Files are labelled WB_Z_ROI_001+orig, etc
    ts_wb_strlabel:
    # type=bool|default=False: by default, '-ts_wb_{corr,Z}' output files are named using the int number of a given ROI, such as: WB_Z_ROI_001+orig. With this option, one can replace the int (such as '001') with the string label (such as 'L-thalamus') *if* one has a labeltable attached to the file
    nifti:
    # type=bool|default=False: output any correlation map files as NIFTI files (default is BRIK/HEAD). Only useful if using '-ts_wb_corr' and/or '-ts_wb_Z'
    output_mask_nonnull:
    # type=bool|default=False: internally, this program checks for where there are nonnull time series, because we don't like those, in general.  With this flag, the user can output the determined mask of non-null time series.
    push_thru_many_zeros:
    # type=bool|default=False: by default, this program will grind to a halt and refuse to calculate if any ROI contains >10 percent of voxels with null times series (i.e., each point is 0), as of April, 2017.  This is because it seems most likely that hidden badness is responsible. However, if the user still wants to carry on the calculation anyways, then this option will allow one to push on through.  However, if any ROI *only* has null time series, then the program will not calculate and the user will really, really, really need to address their masking
    ignore_LT:
    # type=bool|default=False: switch to ignore any label table labels in the '-in_rois' file, if there are any labels attached
    out_file:
    # type=file|default=<undefined>: output file name part
    num_threads:
    # type=int|default=1: set number of threads
    outputtype:
    # type=enum|default='AFNI'|allowed['AFNI','NIFTI','NIFTI_GZ']: AFNI output filetype
    args:
    # type=str|default='': Additional parameters to the command
    environ:
    # type=dict|default={}: Environment variables
  imports:
  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    in_file:
    # type=file|default=<undefined>: input time series file (4D data set)
    mask:
    # type=file|default=<undefined>: can include a whole brain mask within which to calculate correlation. Otherwise, data should be masked already
    in_rois:
    # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
    ts_wb_corr: 'True'
    # type=bool|default=False: switch to create a set of whole brain correlation maps. Performs whole brain correlation for each ROI's average time series; this will automatically create a directory for each network that contains the set of whole brain correlation maps (Pearson 'r's). The directories are labelled as above for '-ts_indiv' Within each directory, the files are labelled WB_CORR_ROI_001+orig, WB_CORR_ROI_002+orig, etc., with the numbers given by the actual ROI integer labels
    ts_wb_Z: 'True'
    # type=bool|default=False: same as above in '-ts_wb_corr', except that the maps have been Fisher transformed to Z-scores the relation: Z=atanh(r). To avoid infinities in the transform, Pearson values are effectively capped at |r| = 0.999329 (where |Z| = 4.0). Files are labelled WB_Z_ROI_001+orig, etc
    fish_z: 'True'
    # type=bool|default=False: switch to also output a matrix of Fisher Z-transform values for the corr coefs (r): Z = atanh(r) , (with Z=4 being output along matrix diagonals where r=1, as the r-to-Z conversion is ceilinged at Z = atanh(r=0.999329) = 4, which is still *quite* a high Pearson-r value
    out_file: '"sub0.tp1.ncorr"'
    # type=file|default=<undefined>: output file name part
  imports:
  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
doctests:
- cmdline: 3dNetCorr -prefix sub0.tp1.ncorr -fish_z -inset functional.nii -in_rois maps.nii -mask mask.nii -ts_wb_Z -ts_wb_corr
  # str - the expected cmdline output
  inputs:
  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
  # If the field is of file-format type and the value is None, then the
  # '.mock()' method of the corresponding class is used instead.
    in_file:
    # type=file|default=<undefined>: input time series file (4D data set)
    mask:
    # type=file|default=<undefined>: can include a whole brain mask within which to calculate correlation. Otherwise, data should be masked already
    in_rois:
    # type=file|default=<undefined>: input set of ROIs, each labelled with distinct integers
    ts_wb_corr: 'True'
    # type=bool|default=False: switch to create a set of whole brain correlation maps. Performs whole brain correlation for each ROI's average time series; this will automatically create a directory for each network that contains the set of whole brain correlation maps (Pearson 'r's). The directories are labelled as above for '-ts_indiv' Within each directory, the files are labelled WB_CORR_ROI_001+orig, WB_CORR_ROI_002+orig, etc., with the numbers given by the actual ROI integer labels
    ts_wb_Z: 'True'
    # type=bool|default=False: same as above in '-ts_wb_corr', except that the maps have been Fisher transformed to Z-scores the relation: Z=atanh(r). To avoid infinities in the transform, Pearson values are effectively capped at |r| = 0.999329 (where |Z| = 4.0). Files are labelled WB_Z_ROI_001+orig, etc
    fish_z: 'True'
    # type=bool|default=False: switch to also output a matrix of Fisher Z-transform values for the corr coefs (r): Z = atanh(r) , (with Z=4 being output along matrix diagonals where r=1, as the r-to-Z conversion is ceilinged at Z = atanh(r=0.999329) = 4, which is still *quite* a high Pearson-r value
    out_file: '"sub0.tp1.ncorr"'
    # type=file|default=<undefined>: output file name part
  imports:
  # list[nipype2pydra.task.base.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  directive:
  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
